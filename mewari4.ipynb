{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb928f80",
   "metadata": {},
   "source": [
    "### Q1. Scrape the details of most viewed videos on YouTube from Wikipedia.\n",
    "### Url = https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos\n",
    "### You need to find following details:\n",
    "### A) Rank\n",
    "### B) Name\n",
    "### C) Artist\n",
    "### D) Upload date\n",
    "### E) Views"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "63966623",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7ce7e2d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_6296\\2226573296.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1c030784",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visiting the website\n",
    "driver.get('https://en.wikipedia.org/wiki/List_of_most-viewed_YouTube_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "552cbd2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rank=[]\n",
    "name=[]\n",
    "artist=[]\n",
    "date=[]\n",
    "views=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "150de477",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Ranks\n",
    "try :\n",
    "    r=driver.find_elements(By.XPATH,'//div[@class=\"mw-parser-output\"]/table[2]/tbody/tr/td')\n",
    "    for i in r[0:181:6]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "#for Names\n",
    "try :\n",
    "    n=driver.find_elements(By.XPATH,'//div[@class=\"mw-parser-output\"]/table[2]/tbody/tr/td')\n",
    "    for i in n[1:181:6]:\n",
    "        name.append(i.text.split('[')[0])\n",
    "except NoSuchElementException :\n",
    "    name.append('-')\n",
    "#for Artists\n",
    "try :\n",
    "    rr=driver.find_elements(By.XPATH,'//div[@class=\"mw-parser-output\"]/table[2]/tbody/tr/td')\n",
    "    for i in rr[2:181:6]:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    artist.append('-')\n",
    "#for Date\n",
    "try :\n",
    "    d=driver.find_elements(By.XPATH,'//div[@class=\"mw-parser-output\"]/table[2]/tbody/tr/td')\n",
    "    for i in d[4:181:6]:\n",
    "        date.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    date.append('-')\n",
    "#for Views\n",
    "try :\n",
    "    v=driver.find_elements(By.XPATH,'//div[@class=\"mw-parser-output\"]/table[2]/tbody/tr/td')\n",
    "    for i in v[3:181:6]:\n",
    "        views.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    views.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "fd858cf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':rank,'Video Name':name,'Artist':artist,'Views(Billion)':views,'Publication date':date})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "d315da18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Video Name</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Views(Billion)</th>\n",
       "      <th>Publication date</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>\"Baby Shark Dance\"</td>\n",
       "      <td>Pinkfong Baby Shark - Kids' Songs &amp; Stories</td>\n",
       "      <td>12.85</td>\n",
       "      <td>June 17, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>\"Despacito\"</td>\n",
       "      <td>Luis Fonsi</td>\n",
       "      <td>8.16</td>\n",
       "      <td>January 12, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>\"Johny Johny Yes Papa\"</td>\n",
       "      <td>LooLoo Kids</td>\n",
       "      <td>6.70</td>\n",
       "      <td>October 8, 2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>\"Bath Song\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>6.20</td>\n",
       "      <td>May 2, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>\"Shape of You\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>6.00</td>\n",
       "      <td>January 30, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6.</td>\n",
       "      <td>\"See You Again\"</td>\n",
       "      <td>Wiz Khalifa</td>\n",
       "      <td>5.89</td>\n",
       "      <td>April 6, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7.</td>\n",
       "      <td>\"Phonics Song with Two Words\"</td>\n",
       "      <td>ChuChu TV</td>\n",
       "      <td>5.30</td>\n",
       "      <td>March 6, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8.</td>\n",
       "      <td>\"Wheels on the Bus\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>5.24</td>\n",
       "      <td>May 24, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9.</td>\n",
       "      <td>\"Uptown Funk\"</td>\n",
       "      <td>Mark Ronson</td>\n",
       "      <td>4.92</td>\n",
       "      <td>November 19, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10.</td>\n",
       "      <td>\"Learning Colors – Colorful Eggs on a Farm\"</td>\n",
       "      <td>Miroshka TV</td>\n",
       "      <td>4.89</td>\n",
       "      <td>February 27, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11.</td>\n",
       "      <td>\"Gangnam Style\"</td>\n",
       "      <td>Psy</td>\n",
       "      <td>4.80</td>\n",
       "      <td>July 15, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12.</td>\n",
       "      <td>\"Masha and the Bear – Recipe for Disaster\"</td>\n",
       "      <td>Get Movies</td>\n",
       "      <td>4.55</td>\n",
       "      <td>January 31, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13.</td>\n",
       "      <td>\"Dame Tu Cosita\"</td>\n",
       "      <td>El Chombo</td>\n",
       "      <td>4.35</td>\n",
       "      <td>April 5, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.</td>\n",
       "      <td>\"Axel F\"</td>\n",
       "      <td>Crazy Frog</td>\n",
       "      <td>3.91</td>\n",
       "      <td>June 16, 2009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15.</td>\n",
       "      <td>\"Sugar\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.87</td>\n",
       "      <td>January 14, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16.</td>\n",
       "      <td>\"Roar\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.80</td>\n",
       "      <td>September 5, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17.</td>\n",
       "      <td>\"Counting Stars\"</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>3.79</td>\n",
       "      <td>May 31, 2013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18.</td>\n",
       "      <td>\"Sorry\"</td>\n",
       "      <td>Justin Bieber</td>\n",
       "      <td>3.66</td>\n",
       "      <td>October 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19.</td>\n",
       "      <td>\"Baa Baa Black Sheep\"</td>\n",
       "      <td>Cocomelon – Nursery Rhymes</td>\n",
       "      <td>3.64</td>\n",
       "      <td>June 25, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20.</td>\n",
       "      <td>\"Thinking Out Loud\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.60</td>\n",
       "      <td>October 7, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21.</td>\n",
       "      <td>\"Waka Waka (This Time for Africa)\"</td>\n",
       "      <td>Shakira</td>\n",
       "      <td>3.59</td>\n",
       "      <td>June 4, 2010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22.</td>\n",
       "      <td>\"Dark Horse\"</td>\n",
       "      <td>Katy Perry</td>\n",
       "      <td>3.52</td>\n",
       "      <td>February 20, 2014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23.</td>\n",
       "      <td>\"Lakdi Ki Kathi\"</td>\n",
       "      <td>Jingle Toons</td>\n",
       "      <td>3.48</td>\n",
       "      <td>June 14, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24.</td>\n",
       "      <td>\"Faded\"</td>\n",
       "      <td>Alan Walker</td>\n",
       "      <td>3.45</td>\n",
       "      <td>December 3, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25.</td>\n",
       "      <td>\"Perfect\"</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>3.45</td>\n",
       "      <td>November 9, 2017</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26.</td>\n",
       "      <td>\"Let Her Go\"</td>\n",
       "      <td>Passenger</td>\n",
       "      <td>3.44</td>\n",
       "      <td>July 25, 2012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27.</td>\n",
       "      <td>\"Girls Like You\"</td>\n",
       "      <td>Maroon 5</td>\n",
       "      <td>3.42</td>\n",
       "      <td>May 31, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28.</td>\n",
       "      <td>\"Humpty the train on a fruits ride\"</td>\n",
       "      <td>Kiddiestv Hindi – Nursery Rhymes &amp; Kids Songs</td>\n",
       "      <td>3.41</td>\n",
       "      <td>January 26, 2018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29.</td>\n",
       "      <td>\"Lean On\"</td>\n",
       "      <td>Major Lazer</td>\n",
       "      <td>3.38</td>\n",
       "      <td>March 22, 2015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30.</td>\n",
       "      <td>\"Bailando\"</td>\n",
       "      <td>Enrique Iglesias</td>\n",
       "      <td>3.38</td>\n",
       "      <td>April 11, 2014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                                   Video Name  \\\n",
       "0    1.                           \"Baby Shark Dance\"   \n",
       "1    2.                                  \"Despacito\"   \n",
       "2    3.                       \"Johny Johny Yes Papa\"   \n",
       "3    4.                                  \"Bath Song\"   \n",
       "4    5.                               \"Shape of You\"   \n",
       "5    6.                              \"See You Again\"   \n",
       "6    7.                \"Phonics Song with Two Words\"   \n",
       "7    8.                          \"Wheels on the Bus\"   \n",
       "8    9.                                \"Uptown Funk\"   \n",
       "9   10.  \"Learning Colors – Colorful Eggs on a Farm\"   \n",
       "10  11.                              \"Gangnam Style\"   \n",
       "11  12.   \"Masha and the Bear – Recipe for Disaster\"   \n",
       "12  13.                             \"Dame Tu Cosita\"   \n",
       "13  14.                                     \"Axel F\"   \n",
       "14  15.                                      \"Sugar\"   \n",
       "15  16.                                       \"Roar\"   \n",
       "16  17.                             \"Counting Stars\"   \n",
       "17  18.                                      \"Sorry\"   \n",
       "18  19.                        \"Baa Baa Black Sheep\"   \n",
       "19  20.                          \"Thinking Out Loud\"   \n",
       "20  21.           \"Waka Waka (This Time for Africa)\"   \n",
       "21  22.                                 \"Dark Horse\"   \n",
       "22  23.                             \"Lakdi Ki Kathi\"   \n",
       "23  24.                                      \"Faded\"   \n",
       "24  25.                                    \"Perfect\"   \n",
       "25  26.                                 \"Let Her Go\"   \n",
       "26  27.                             \"Girls Like You\"   \n",
       "27  28.          \"Humpty the train on a fruits ride\"   \n",
       "28  29.                                    \"Lean On\"   \n",
       "29  30.                                   \"Bailando\"   \n",
       "\n",
       "                                           Artist Views(Billion)  \\\n",
       "0     Pinkfong Baby Shark - Kids' Songs & Stories          12.85   \n",
       "1                                      Luis Fonsi           8.16   \n",
       "2                                     LooLoo Kids           6.70   \n",
       "3                      Cocomelon – Nursery Rhymes           6.20   \n",
       "4                                      Ed Sheeran           6.00   \n",
       "5                                     Wiz Khalifa           5.89   \n",
       "6                                       ChuChu TV           5.30   \n",
       "7                      Cocomelon – Nursery Rhymes           5.24   \n",
       "8                                     Mark Ronson           4.92   \n",
       "9                                     Miroshka TV           4.89   \n",
       "10                                            Psy           4.80   \n",
       "11                                     Get Movies           4.55   \n",
       "12                                      El Chombo           4.35   \n",
       "13                                     Crazy Frog           3.91   \n",
       "14                                       Maroon 5           3.87   \n",
       "15                                     Katy Perry           3.80   \n",
       "16                                    OneRepublic           3.79   \n",
       "17                                  Justin Bieber           3.66   \n",
       "18                     Cocomelon – Nursery Rhymes           3.64   \n",
       "19                                     Ed Sheeran           3.60   \n",
       "20                                        Shakira           3.59   \n",
       "21                                     Katy Perry           3.52   \n",
       "22                                   Jingle Toons           3.48   \n",
       "23                                    Alan Walker           3.45   \n",
       "24                                     Ed Sheeran           3.45   \n",
       "25                                      Passenger           3.44   \n",
       "26                                       Maroon 5           3.42   \n",
       "27  Kiddiestv Hindi – Nursery Rhymes & Kids Songs           3.41   \n",
       "28                                    Major Lazer           3.38   \n",
       "29                               Enrique Iglesias           3.38   \n",
       "\n",
       "     Publication date  \n",
       "0       June 17, 2016  \n",
       "1    January 12, 2017  \n",
       "2     October 8, 2016  \n",
       "3         May 2, 2018  \n",
       "4    January 30, 2017  \n",
       "5       April 6, 2015  \n",
       "6       March 6, 2014  \n",
       "7        May 24, 2018  \n",
       "8   November 19, 2014  \n",
       "9   February 27, 2018  \n",
       "10      July 15, 2012  \n",
       "11   January 31, 2012  \n",
       "12      April 5, 2018  \n",
       "13      June 16, 2009  \n",
       "14   January 14, 2015  \n",
       "15  September 5, 2013  \n",
       "16       May 31, 2013  \n",
       "17   October 22, 2015  \n",
       "18      June 25, 2018  \n",
       "19    October 7, 2014  \n",
       "20       June 4, 2010  \n",
       "21  February 20, 2014  \n",
       "22      June 14, 2018  \n",
       "23   December 3, 2015  \n",
       "24   November 9, 2017  \n",
       "25      July 25, 2012  \n",
       "26       May 31, 2018  \n",
       "27   January 26, 2018  \n",
       "28     March 22, 2015  \n",
       "29     April 11, 2014  "
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2fad447",
   "metadata": {},
   "source": [
    "### 2. Scrape the details team India’s international fixtures from bcci.tv.\n",
    "### Url = https://www.bcci.tv/.\n",
    "### You need to find following details:\n",
    "### A) Match title (I.e. 1st ODI)\n",
    "### B) Series\n",
    "### C) Place\n",
    "### D) Date\n",
    "### E) Time\n",
    "### Note: - From bcci.tv home page you have reach to the international fixture page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b7e551",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0a951a38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_7516\\2036329996.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "#Visiting the website\n",
    "driver.get('https://www.bcci.tv/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b88081a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"navigation\"]/ul[1]/li[2]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3e931d0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Series=[]\n",
    "Place=[]\n",
    "Date=[]\n",
    "Time=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "5b6edb90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Match title\n",
    "try :\n",
    "    title=driver.find_element(By.XPATH,'//*[@id=\"match-card\"]/div[1]/h5')\n",
    "    Title.append(title.text)\n",
    "except NoSuchElementException :\n",
    "    Title.append('-')\n",
    "# For Series\n",
    "try :\n",
    "    series=driver.find_element(By.XPATH,'//*[@id=\"match-card\"]/div[1]/h5')\n",
    "    Series.append(series.text.split('D')[1].split('C')[0])\n",
    "except NoSuchElementException :\n",
    "    Series.append('-')\n",
    "# For Place\n",
    "try :\n",
    "    place=driver.find_element(By.XPATH,'//*[@id=\"match-card\"]/div[3]/div')\n",
    "    Place.append(place.text.split('-')[1])\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    Place.append('-')\n",
    "# For Date\n",
    "try :\n",
    "    date=driver.find_element(By.XPATH,'//*[@id=\"match-card\"]/div[1]/div/div[1]')\n",
    "    Date.append(date.text)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    Date.append('-')\n",
    "# For Time\n",
    "try :\n",
    "    time=driver.find_element(By.XPATH,'//*[@id=\"match-card\"]/div[1]/div/div[2]')\n",
    "    Time.append(time.text)\n",
    "    \n",
    "except NoSuchElementException :\n",
    "    Time.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf57fb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Match Title':Title,'Series':Series,'Place':Place,'Date':Date,'Time':Time})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1d22eed5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Match Title</th>\n",
       "      <th>Series</th>\n",
       "      <th>Place</th>\n",
       "      <th>Date</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ICC WORLD TEST CHAMPIONSHIP FINAL 2023</td>\n",
       "      <td>TEST</td>\n",
       "      <td>Kennington Oval, London</td>\n",
       "      <td>7 JUN 2023</td>\n",
       "      <td>3:30 PM IST</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Match Title  Series                     Place  \\\n",
       "0  ICC WORLD TEST CHAMPIONSHIP FINAL 2023   TEST    Kennington Oval, London   \n",
       "\n",
       "         Date         Time  \n",
       "0  7 JUN 2023  3:30 PM IST  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51954336",
   "metadata": {},
   "source": [
    "### 3. Scrape the details of State-wise GDP of India from statisticstime.com.\n",
    "### Url = http://statisticstimes.com/\n",
    "### You have to find following details:\n",
    "### A) Rank\n",
    "### B) State\n",
    "### C) GSDP(18-19)- at current prices\n",
    "### D) GSDP(19-20)- at current prices\n",
    "### E) Share(18-19)\n",
    "### F) GDP($ billion)\n",
    "### Note: - From statisticstimes home page you have to reach to economy page through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "fa1b5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bbc0681e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_6296\\2226573296.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "65d2ff6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visiting the website\n",
    "driver.get('https://www.statisticstimes.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "224e7854",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/button').click()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "9f4c7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"top\"]/div[2]/div[2]/div/a[3]').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "f788c55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element(By.XPATH,'/html/body/div[2]/div[2]/div[2]/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "6dbef3fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "State=[]\n",
    "GSDP1=[]\n",
    "GSDP2=[]\n",
    "Share=[]\n",
    "GDP=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e86c1d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Ranks\n",
    "try :\n",
    "    rank=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in rank[0:264:8]:\n",
    "        Rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Rank.append('-')\n",
    "#for State\n",
    "try :\n",
    "    state=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in state[1:264:8]:\n",
    "        State.append(i.text.split('[')[0])\n",
    "except NoSuchElementException :\n",
    "    State.append('-')\n",
    "#for GSDP1\n",
    "try :\n",
    "    gsdp1=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in gsdp1[3:264:8]:\n",
    "        GSDP1.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    GSDP1.append('-')\n",
    "#for GSDP2\n",
    "try :\n",
    "    gsdp2=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in gsdp2[2:264:8]:\n",
    "        GSDP2.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    GSDP2.append('-')\n",
    "#for Share\n",
    "try :\n",
    "    share=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in share[4:264:8]:\n",
    "        Share.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Share.append('-')\n",
    "# GDP\n",
    "try :\n",
    "    gdp=driver.find_elements(By.XPATH,'//div[@id=\"main\"]/div[5]/div/div/table/tbody/tr/td')\n",
    "    for i in gdp[5:264:8]:\n",
    "        GDP.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    GDP.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "874ebff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Rank':Rank,'State':State,'GSDP(18-19)- at current prices':GSDP1,'GSDP(19-20)- at current prices':GSDP2,'Share(18-19)':Share,'GDP($ billio)':GDP})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "26c3babe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>State</th>\n",
       "      <th>GSDP(18-19)- at current prices</th>\n",
       "      <th>GSDP(19-20)- at current prices</th>\n",
       "      <th>Share(18-19)</th>\n",
       "      <th>GDP($ billio)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Maharashtra</td>\n",
       "      <td>2,632,792</td>\n",
       "      <td>-</td>\n",
       "      <td>13.94%</td>\n",
       "      <td>399.921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Tamil Nadu</td>\n",
       "      <td>1,630,208</td>\n",
       "      <td>1,845,853</td>\n",
       "      <td>8.63%</td>\n",
       "      <td>247.629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Uttar Pradesh</td>\n",
       "      <td>1,584,764</td>\n",
       "      <td>1,687,818</td>\n",
       "      <td>8.39%</td>\n",
       "      <td>240.726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Gujarat</td>\n",
       "      <td>1,502,899</td>\n",
       "      <td>-</td>\n",
       "      <td>7.96%</td>\n",
       "      <td>228.290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Karnataka</td>\n",
       "      <td>1,493,127</td>\n",
       "      <td>1,631,977</td>\n",
       "      <td>7.91%</td>\n",
       "      <td>226.806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>West Bengal</td>\n",
       "      <td>1,089,898</td>\n",
       "      <td>1,253,832</td>\n",
       "      <td>5.77%</td>\n",
       "      <td>165.556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>Rajasthan</td>\n",
       "      <td>942,586</td>\n",
       "      <td>1,020,989</td>\n",
       "      <td>4.99%</td>\n",
       "      <td>143.179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>Andhra Pradesh</td>\n",
       "      <td>862,957</td>\n",
       "      <td>972,782</td>\n",
       "      <td>4.57%</td>\n",
       "      <td>131.083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>Telangana</td>\n",
       "      <td>861,031</td>\n",
       "      <td>969,604</td>\n",
       "      <td>4.56%</td>\n",
       "      <td>130.791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>Madhya Pradesh</td>\n",
       "      <td>809,592</td>\n",
       "      <td>906,672</td>\n",
       "      <td>4.29%</td>\n",
       "      <td>122.977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>Kerala</td>\n",
       "      <td>781,653</td>\n",
       "      <td>-</td>\n",
       "      <td>4.14%</td>\n",
       "      <td>118.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>Delhi</td>\n",
       "      <td>774,870</td>\n",
       "      <td>856,112</td>\n",
       "      <td>4.10%</td>\n",
       "      <td>117.703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>Haryana</td>\n",
       "      <td>734,163</td>\n",
       "      <td>831,610</td>\n",
       "      <td>3.89%</td>\n",
       "      <td>111.519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>Bihar</td>\n",
       "      <td>530,363</td>\n",
       "      <td>611,804</td>\n",
       "      <td>2.81%</td>\n",
       "      <td>80.562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>Punjab</td>\n",
       "      <td>526,376</td>\n",
       "      <td>574,760</td>\n",
       "      <td>2.79%</td>\n",
       "      <td>79.957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>Odisha</td>\n",
       "      <td>487,805</td>\n",
       "      <td>521,275</td>\n",
       "      <td>2.58%</td>\n",
       "      <td>74.098</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>Assam</td>\n",
       "      <td>315,881</td>\n",
       "      <td>-</td>\n",
       "      <td>1.67%</td>\n",
       "      <td>47.982</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>Chhattisgarh</td>\n",
       "      <td>304,063</td>\n",
       "      <td>329,180</td>\n",
       "      <td>1.61%</td>\n",
       "      <td>46.187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>Jharkhand</td>\n",
       "      <td>297,204</td>\n",
       "      <td>328,598</td>\n",
       "      <td>1.57%</td>\n",
       "      <td>45.145</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>Uttarakhand</td>\n",
       "      <td>245,895</td>\n",
       "      <td>-</td>\n",
       "      <td>1.30%</td>\n",
       "      <td>37.351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>Jammu &amp; Kashmir</td>\n",
       "      <td>155,956</td>\n",
       "      <td>-</td>\n",
       "      <td>0.83%</td>\n",
       "      <td>23.690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>Himachal Pradesh</td>\n",
       "      <td>153,845</td>\n",
       "      <td>165,472</td>\n",
       "      <td>0.81%</td>\n",
       "      <td>23.369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>Goa</td>\n",
       "      <td>73,170</td>\n",
       "      <td>80,449</td>\n",
       "      <td>0.39%</td>\n",
       "      <td>11.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>Tripura</td>\n",
       "      <td>49,845</td>\n",
       "      <td>55,984</td>\n",
       "      <td>0.26%</td>\n",
       "      <td>7.571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>Chandigarh</td>\n",
       "      <td>42,114</td>\n",
       "      <td>-</td>\n",
       "      <td>0.22%</td>\n",
       "      <td>6.397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>Puducherry</td>\n",
       "      <td>34,433</td>\n",
       "      <td>38,253</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>Meghalaya</td>\n",
       "      <td>33,481</td>\n",
       "      <td>36,572</td>\n",
       "      <td>0.18%</td>\n",
       "      <td>5.086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>Sikkim</td>\n",
       "      <td>28,723</td>\n",
       "      <td>32,496</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>Manipur</td>\n",
       "      <td>27,870</td>\n",
       "      <td>31,790</td>\n",
       "      <td>0.15%</td>\n",
       "      <td>4.233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>Nagaland</td>\n",
       "      <td>27,283</td>\n",
       "      <td>-</td>\n",
       "      <td>0.14%</td>\n",
       "      <td>4.144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31</td>\n",
       "      <td>Arunachal Pradesh</td>\n",
       "      <td>24,603</td>\n",
       "      <td>-</td>\n",
       "      <td>0.13%</td>\n",
       "      <td>3.737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>32</td>\n",
       "      <td>Mizoram</td>\n",
       "      <td>22,287</td>\n",
       "      <td>26,503</td>\n",
       "      <td>0.12%</td>\n",
       "      <td>3.385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>33</td>\n",
       "      <td>Andaman &amp; Nicobar Islands</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank                      State GSDP(18-19)- at current prices  \\\n",
       "0     1                Maharashtra                      2,632,792   \n",
       "1     2                 Tamil Nadu                      1,630,208   \n",
       "2     3              Uttar Pradesh                      1,584,764   \n",
       "3     4                    Gujarat                      1,502,899   \n",
       "4     5                  Karnataka                      1,493,127   \n",
       "5     6                West Bengal                      1,089,898   \n",
       "6     7                  Rajasthan                        942,586   \n",
       "7     8             Andhra Pradesh                        862,957   \n",
       "8     9                  Telangana                        861,031   \n",
       "9    10             Madhya Pradesh                        809,592   \n",
       "10   11                     Kerala                        781,653   \n",
       "11   12                      Delhi                        774,870   \n",
       "12   13                    Haryana                        734,163   \n",
       "13   14                      Bihar                        530,363   \n",
       "14   15                     Punjab                        526,376   \n",
       "15   16                     Odisha                        487,805   \n",
       "16   17                      Assam                        315,881   \n",
       "17   18               Chhattisgarh                        304,063   \n",
       "18   19                  Jharkhand                        297,204   \n",
       "19   20                Uttarakhand                        245,895   \n",
       "20   21            Jammu & Kashmir                        155,956   \n",
       "21   22           Himachal Pradesh                        153,845   \n",
       "22   23                        Goa                         73,170   \n",
       "23   24                    Tripura                         49,845   \n",
       "24   25                 Chandigarh                         42,114   \n",
       "25   26                 Puducherry                         34,433   \n",
       "26   27                  Meghalaya                         33,481   \n",
       "27   28                     Sikkim                         28,723   \n",
       "28   29                    Manipur                         27,870   \n",
       "29   30                   Nagaland                         27,283   \n",
       "30   31          Arunachal Pradesh                         24,603   \n",
       "31   32                    Mizoram                         22,287   \n",
       "32   33  Andaman & Nicobar Islands                              -   \n",
       "\n",
       "   GSDP(19-20)- at current prices Share(18-19) GDP($ billio)  \n",
       "0                               -       13.94%       399.921  \n",
       "1                       1,845,853        8.63%       247.629  \n",
       "2                       1,687,818        8.39%       240.726  \n",
       "3                               -        7.96%       228.290  \n",
       "4                       1,631,977        7.91%       226.806  \n",
       "5                       1,253,832        5.77%       165.556  \n",
       "6                       1,020,989        4.99%       143.179  \n",
       "7                         972,782        4.57%       131.083  \n",
       "8                         969,604        4.56%       130.791  \n",
       "9                         906,672        4.29%       122.977  \n",
       "10                              -        4.14%       118.733  \n",
       "11                        856,112        4.10%       117.703  \n",
       "12                        831,610        3.89%       111.519  \n",
       "13                        611,804        2.81%        80.562  \n",
       "14                        574,760        2.79%        79.957  \n",
       "15                        521,275        2.58%        74.098  \n",
       "16                              -        1.67%        47.982  \n",
       "17                        329,180        1.61%        46.187  \n",
       "18                        328,598        1.57%        45.145  \n",
       "19                              -        1.30%        37.351  \n",
       "20                              -        0.83%        23.690  \n",
       "21                        165,472        0.81%        23.369  \n",
       "22                         80,449        0.39%        11.115  \n",
       "23                         55,984        0.26%         7.571  \n",
       "24                              -        0.22%         6.397  \n",
       "25                         38,253        0.18%         5.230  \n",
       "26                         36,572        0.18%         5.086  \n",
       "27                         32,496        0.15%         4.363  \n",
       "28                         31,790        0.15%         4.233  \n",
       "29                              -        0.14%         4.144  \n",
       "30                              -        0.13%         3.737  \n",
       "31                         26,503        0.12%         3.385  \n",
       "32                              -            -             -  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dcd1dea",
   "metadata": {},
   "source": [
    "### 4. Scrape the details of trending repositories on Github.com.\n",
    "### Url = https://github.com/\n",
    "### You have to find the following details:\n",
    "### A) Repository title\n",
    "### B) Repository description\n",
    "### C) Contributors count\n",
    "### D) Language used\n",
    "### Note: - From the home page you have to click on the trending option from Explore menu through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "f41ecd06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "dcd01d7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_7516\\1289357361.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "#Visiting the website\n",
    "driver.get('https://github.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7bacbcb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"feed-item-0\"]/header/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ea67a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "Title=[]\n",
    "Description=[]\n",
    "Contributor=[]\n",
    "Language=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "bd987ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Titles\n",
    "try :\n",
    "    title=driver.find_elements(By.XPATH,'//h2[@class=\"h3 lh-condensed\"]')\n",
    "    for i in title[0:24]:\n",
    "        Title.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Title.append('-')\n",
    "#for Description\n",
    "try :\n",
    "    description=driver.find_elements(By.XPATH,'//p[@class=\"col-9 color-fg-muted my-1 pr-4\"]')\n",
    "    for i in description:\n",
    "        Description.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Description.append('-')\n",
    "#for Contributor\n",
    "try :\n",
    "    contributor=driver.find_elements(By.XPATH,'//a[@class=\"Link--muted d-inline-block mr-3\"]')\n",
    "    for i in contributor[0:48:2]:\n",
    "        Contributor.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Contributor.append('-')\n",
    "#for Language\n",
    "try :\n",
    "    language=driver.find_elements(By.XPATH,'//span[@class=\"d-inline-block ml-0 mr-3\"]')\n",
    "    for i in language:\n",
    "        Language.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Language.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "884723f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Repository title':Title,'Repository description':Description,'Contributors count':Contributor,'Language used':Language})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fa540232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Repository title</th>\n",
       "      <th>Repository description</th>\n",
       "      <th>Contributors count</th>\n",
       "      <th>Language used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Zeqiang-Lai / DragGAN</td>\n",
       "      <td>Online Demo and Implementation of DragGAN - \"D...</td>\n",
       "      <td>2,257</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JiauZhang / DragGAN</td>\n",
       "      <td>Implementation of DragGAN: Interactive Point-b...</td>\n",
       "      <td>1,736</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>google / comprehensive-rust</td>\n",
       "      <td>This is the Rust course used by the Android te...</td>\n",
       "      <td>15,922</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kyegomez / tree-of-thoughts</td>\n",
       "      <td>Plug in and Play Implementation of Tree of Tho...</td>\n",
       "      <td>1,337</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>microsoft / PowerToys</td>\n",
       "      <td>Windows system utilities to maximize productivity</td>\n",
       "      <td>91,277</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>psf / requests</td>\n",
       "      <td>A simple, yet elegant, HTTP library.</td>\n",
       "      <td>49,690</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kanboard / kanboard</td>\n",
       "      <td>Kanban project management software</td>\n",
       "      <td>7,488</td>\n",
       "      <td>PHP</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>microsoft / devhome</td>\n",
       "      <td>Windows Dev Home Application</td>\n",
       "      <td>1,120</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dalathegreat / BYD-Battery-Emulator-For-Gen24</td>\n",
       "      <td>This software converts the LEAF CAN into Modbu...</td>\n",
       "      <td>204</td>\n",
       "      <td>C++</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>kamiyaa / joshuto</td>\n",
       "      <td>ranger-like terminal file manager written in Rust</td>\n",
       "      <td>1,948</td>\n",
       "      <td>Rust</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>JushBJJ / Mr.-Ranedeer-AI-Tutor</td>\n",
       "      <td>A GPT-4 AI Tutor Prompt for customizable perso...</td>\n",
       "      <td>8,868</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>NaiboWang / EasySpider</td>\n",
       "      <td>A visual no-code/code-free web crawler/spider一...</td>\n",
       "      <td>7,061</td>\n",
       "      <td>JavaScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>chinese-poetry / chinese-poetry</td>\n",
       "      <td>The most comprehensive database of Chinese poe...</td>\n",
       "      <td>40,749</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>pengzhile / pandora</td>\n",
       "      <td>潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT that h...</td>\n",
       "      <td>9,129</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>facebookresearch / fairseq</td>\n",
       "      <td>Facebook AI Research Sequence-to-Sequence Tool...</td>\n",
       "      <td>25,492</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>SkalskiP / courses</td>\n",
       "      <td>This repository is a curated collection of lin...</td>\n",
       "      <td>2,524</td>\n",
       "      <td>C#</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>microsoft / semantic-kernel</td>\n",
       "      <td>Integrate cutting-edge LLM technology quickly ...</td>\n",
       "      <td>9,313</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>kreneskyp / ix</td>\n",
       "      <td>Autonomous GPT-4 agent platform</td>\n",
       "      <td>404</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>OpenGVLab / InternGPT</td>\n",
       "      <td>InternGPT (iGPT) is an open source demo platfo...</td>\n",
       "      <td>1,089</td>\n",
       "      <td>TypeScript</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>w-okada / voice-changer</td>\n",
       "      <td>リアルタイムボイスチェンジャー Realtime Voice Changer</td>\n",
       "      <td>3,861</td>\n",
       "      <td>HTML</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>adams549659584 / go-proxy-bingai</td>\n",
       "      <td>用 Vue3 和 Go 搭建的微软 New Bing 演示站点，拥有一致的 UI 体验，支持...</td>\n",
       "      <td>1,477</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>opengeos / segment-geospatial</td>\n",
       "      <td>A Python package for segmenting geospatial dat...</td>\n",
       "      <td>1,519</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Azure-Samples / azure-search-openai-demo</td>\n",
       "      <td>A sample app for the Retrieval-Augmented Gener...</td>\n",
       "      <td>2,170</td>\n",
       "      <td>Jupyter Notebook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>openai / openai-cookbook</td>\n",
       "      <td>Examples and guides for using the OpenAI API</td>\n",
       "      <td>36,711</td>\n",
       "      <td>Python</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 Repository title  \\\n",
       "0                           Zeqiang-Lai / DragGAN   \n",
       "1                             JiauZhang / DragGAN   \n",
       "2                     google / comprehensive-rust   \n",
       "3                     kyegomez / tree-of-thoughts   \n",
       "4                           microsoft / PowerToys   \n",
       "5                                  psf / requests   \n",
       "6                             kanboard / kanboard   \n",
       "7                             microsoft / devhome   \n",
       "8   dalathegreat / BYD-Battery-Emulator-For-Gen24   \n",
       "9                               kamiyaa / joshuto   \n",
       "10                JushBJJ / Mr.-Ranedeer-AI-Tutor   \n",
       "11                         NaiboWang / EasySpider   \n",
       "12                chinese-poetry / chinese-poetry   \n",
       "13                            pengzhile / pandora   \n",
       "14                     facebookresearch / fairseq   \n",
       "15                             SkalskiP / courses   \n",
       "16                    microsoft / semantic-kernel   \n",
       "17                                 kreneskyp / ix   \n",
       "18                          OpenGVLab / InternGPT   \n",
       "19                        w-okada / voice-changer   \n",
       "20               adams549659584 / go-proxy-bingai   \n",
       "21                  opengeos / segment-geospatial   \n",
       "22       Azure-Samples / azure-search-openai-demo   \n",
       "23                       openai / openai-cookbook   \n",
       "\n",
       "                               Repository description Contributors count  \\\n",
       "0   Online Demo and Implementation of DragGAN - \"D...              2,257   \n",
       "1   Implementation of DragGAN: Interactive Point-b...              1,736   \n",
       "2   This is the Rust course used by the Android te...             15,922   \n",
       "3   Plug in and Play Implementation of Tree of Tho...              1,337   \n",
       "4   Windows system utilities to maximize productivity             91,277   \n",
       "5                A simple, yet elegant, HTTP library.             49,690   \n",
       "6                  Kanban project management software              7,488   \n",
       "7                        Windows Dev Home Application              1,120   \n",
       "8   This software converts the LEAF CAN into Modbu...                204   \n",
       "9   ranger-like terminal file manager written in Rust              1,948   \n",
       "10  A GPT-4 AI Tutor Prompt for customizable perso...              8,868   \n",
       "11  A visual no-code/code-free web crawler/spider一...              7,061   \n",
       "12  The most comprehensive database of Chinese poe...             40,749   \n",
       "13  潘多拉，一个让你呼吸顺畅的ChatGPT。Pandora, a ChatGPT that h...              9,129   \n",
       "14  Facebook AI Research Sequence-to-Sequence Tool...             25,492   \n",
       "15  This repository is a curated collection of lin...              2,524   \n",
       "16  Integrate cutting-edge LLM technology quickly ...              9,313   \n",
       "17                    Autonomous GPT-4 agent platform                404   \n",
       "18  InternGPT (iGPT) is an open source demo platfo...              1,089   \n",
       "19             リアルタイムボイスチェンジャー Realtime Voice Changer              3,861   \n",
       "20  用 Vue3 和 Go 搭建的微软 New Bing 演示站点，拥有一致的 UI 体验，支持...              1,477   \n",
       "21  A Python package for segmenting geospatial dat...              1,519   \n",
       "22  A sample app for the Retrieval-Augmented Gener...              2,170   \n",
       "23       Examples and guides for using the OpenAI API             36,711   \n",
       "\n",
       "       Language used  \n",
       "0             Python  \n",
       "1             Python  \n",
       "2               Rust  \n",
       "3             Python  \n",
       "4                 C#  \n",
       "5             Python  \n",
       "6                PHP  \n",
       "7                 C#  \n",
       "8                C++  \n",
       "9               Rust  \n",
       "10        JavaScript  \n",
       "11        JavaScript  \n",
       "12            Python  \n",
       "13            Python  \n",
       "14            Python  \n",
       "15                C#  \n",
       "16            Python  \n",
       "17            Python  \n",
       "18        TypeScript  \n",
       "19              HTML  \n",
       "20            Python  \n",
       "21            Python  \n",
       "22  Jupyter Notebook  \n",
       "23            Python  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "695bbffc",
   "metadata": {},
   "source": [
    "### 5. Scrape the details of top 100 songs on billiboard.com.\n",
    "### Url = https:/www.billboard.com/\n",
    "### You have to find the following details:\n",
    "### A) Song name\n",
    "### B) Artist name\n",
    "### C) Last week rank\n",
    "### D) Peak rank\n",
    "### E) Weeks on board\n",
    "### Note: - From the home page you have to click on the charts option then hot 100-page link through code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3472c674",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e276d356",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_5068\\1406918779.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "#Visiting the website\n",
    "driver.get('http://www.billboard.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10382415",
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/header/div/div[2]/div/div/div[2]/div[2]/div/div/nav/ul/li[1]/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0b799872",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "driver.find_element(By.XPATH,'//*[@id=\"main-wrapper\"]/main/div[2]/div[1]/div[1]/div/div/div[1]/div[1]/div[2]/span/a').click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "86cd7df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "song=[]\n",
    "artist=[]\n",
    "rank=[]\n",
    "prank=[]\n",
    "board=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "2f505ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#for Song names\n",
    "try :\n",
    "    title=driver.find_elements(By.TAG_NAME,'h3')\n",
    "    for i in title[7:405:4]:\n",
    "        song.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    song.append('-')\n",
    "\n",
    "# for artist name\n",
    "#for 1st song artist we use xpatho 1st artist because its different from other\n",
    "t=driver.find_element(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[1]/span')\n",
    "artist.append(t.text)\n",
    "try:\n",
    "    tt=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-no-trucate a-font-primary-s lrv-u-font-size-14@mobile-max u-line-height-normal@mobile-max u-letter-spacing-0021 lrv-u-display-block a-truncate-ellipsis-2line u-max-width-330 u-max-width-230@tablet-only\"]')\n",
    "    for i in tt:\n",
    "        artist.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    artist.append('-')\n",
    "# for Rank \n",
    "#for 1st rank we use xpatho 1st artist because its different from other\n",
    "r=driver.find_element(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[4]/span')\n",
    "rank.append(r.text)\n",
    "try:\n",
    "    rr=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "    for i in rr[0:594:6]:\n",
    "        rank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    rank.append('-')\n",
    "# for Peak Rank \n",
    "#for 1st peak rank we use xpath of 1st artist because its different from other\n",
    "p=driver.find_element(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[2]/ul/li[4]/ul/li[5]/span')\n",
    "prank.append(p.text)\n",
    "try:\n",
    "    pp=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "    for i in pp[1:594:6]:\n",
    "        prank.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    prank.append('-')\n",
    "# for weeks on board \n",
    "#for 1st week on board we use xpath of 1st artist because its different from other\n",
    "b=driver.find_element(By.XPATH,'//*[@id=\"post-1479786\"]/div[3]/div/div/div/div[2]/div[3]/ul/li[4]/ul/li[6]/span')\n",
    "board.append(b.text)\n",
    "try:\n",
    "    bb=driver.find_elements(By.XPATH,'//span[@class=\"c-label  a-font-primary-m lrv-u-padding-tb-050@mobile-max\"]')\n",
    "    for i in bb[2:594:6]:\n",
    "        board.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    board.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e0f68713",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Song name':song,'Last week rank':rank,'Peak rank':prank,'Weeks on board':board})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5f401b7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Song name</th>\n",
       "      <th>Last week rank</th>\n",
       "      <th>Peak rank</th>\n",
       "      <th>Weeks on board</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Last Night</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>All My Life</td>\n",
       "      <td>-</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Flowers</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Kill Bill</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ella Baila Sola</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Forever</td>\n",
       "      <td>87</td>\n",
       "      <td>8</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Private Landing</td>\n",
       "      <td>100</td>\n",
       "      <td>72</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>I Heard</td>\n",
       "      <td>-</td>\n",
       "      <td>98</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Sunrise</td>\n",
       "      <td>89</td>\n",
       "      <td>30</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Happy</td>\n",
       "      <td>95</td>\n",
       "      <td>54</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Song name Last week rank Peak rank Weeks on board\n",
       "0        Last Night              1         1              1\n",
       "1       All My Life              -         2              1\n",
       "2           Flowers              3         1             18\n",
       "3         Kill Bill              2         1             23\n",
       "4   Ella Baila Sola              4         4              9\n",
       "..              ...            ...       ...            ...\n",
       "95          Forever             87         8             19\n",
       "96  Private Landing            100        72              6\n",
       "97          I Heard              -        98              1\n",
       "98          Sunrise             89        30             11\n",
       "99            Happy             95        54              6\n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6f4b88",
   "metadata": {},
   "source": [
    "### 6. Scrape the details of Highest sellingnovels.\n",
    "### Url = https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-greycompare\n",
    "### You have to find the following details:\n",
    "### A) Book name\n",
    "### B) Author name\n",
    "### C) Volumes sold\n",
    "### D) Publisher\n",
    "### E) Genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "fe1e259d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "12873d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_5068\\1301127348.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "#Visiting the website\n",
    "driver.get('https://www.theguardian.com/news/datablog/2012/aug/09/best-selling-books-all-time-fifty-shades-grey-compare')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "18fc6f9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "book=[]\n",
    "author=[]\n",
    "volume=[]\n",
    "publisher=[]\n",
    "genre=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "cefc76d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Book names\n",
    "try :\n",
    "    b=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "    for i in b[1:500:5]:\n",
    "        book.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    book.append('-')\n",
    "#for author name\n",
    "try :\n",
    "    a=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "    for i in a[2:500:5]:\n",
    "        author.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    author.append('-')\n",
    "#for volumes sold\n",
    "try :\n",
    "    v=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "    for i in v[3:500:5]:\n",
    "        volume.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    volume.append('-')\n",
    "#for Publisher name\n",
    "try :\n",
    "    p=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "    for i in p[4:500:5]:\n",
    "        publisher.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    publisher.append('-')\n",
    "#for genre\n",
    "try :\n",
    "    g=driver.find_elements(By.XPATH,'//td[@class=\"left\"]')\n",
    "    for i in g[5:500:5]:\n",
    "        genre.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    genre.append('-')\n",
    "# As we are using xpath of class for everthing but for genre the last book's class is different therefore we will scrape it separatly\n",
    "gg=driver.find_element(By.XPATH,'//*[@id=\"table-cell-10943-99-5\"]')\n",
    "genre.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "bdab50d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Book name':book,'Author name':author,'Volumes sold':volume,'Publisher':publisher,'Genre':genre})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "3fe8baf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Book name</th>\n",
       "      <th>Author name</th>\n",
       "      <th>Volumes sold</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Da Vinci Code,The</td>\n",
       "      <td>Brown, Dan</td>\n",
       "      <td>5,094,805</td>\n",
       "      <td>Transworld</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Harry Potter and the Deathly Hallows</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,475,152</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Harry Potter and the Philosopher's Stone</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,200,654</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Potter and the Order of the Phoenix</td>\n",
       "      <td>Rowling, J.K.</td>\n",
       "      <td>4,179,479</td>\n",
       "      <td>Bloomsbury</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fifty Shades of Grey</td>\n",
       "      <td>James, E. L.</td>\n",
       "      <td>3,758,936</td>\n",
       "      <td>Random House</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Ghost,The</td>\n",
       "      <td>Harris, Robert</td>\n",
       "      <td>807,311</td>\n",
       "      <td>Random House</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Happy Days with the Naked Chef</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>794,201</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>98</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Hunger Games,The:Hunger Games Trilogy</td>\n",
       "      <td>Collins, Suzanne</td>\n",
       "      <td>792,187</td>\n",
       "      <td>Scholastic Ltd.</td>\n",
       "      <td>99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Lost Boy,The:A Foster Child's Search for the L...</td>\n",
       "      <td>Pelzer, Dave</td>\n",
       "      <td>791,507</td>\n",
       "      <td>Orion</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Jamie's Ministry of Food:Anyone Can Learn to C...</td>\n",
       "      <td>Oliver, Jamie</td>\n",
       "      <td>791,095</td>\n",
       "      <td>Penguin</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Book name       Author name  \\\n",
       "0                                   Da Vinci Code,The        Brown, Dan   \n",
       "1                Harry Potter and the Deathly Hallows     Rowling, J.K.   \n",
       "2            Harry Potter and the Philosopher's Stone     Rowling, J.K.   \n",
       "3           Harry Potter and the Order of the Phoenix     Rowling, J.K.   \n",
       "4                                Fifty Shades of Grey      James, E. L.   \n",
       "..                                                ...               ...   \n",
       "95                                          Ghost,The    Harris, Robert   \n",
       "96                     Happy Days with the Naked Chef     Oliver, Jamie   \n",
       "97              Hunger Games,The:Hunger Games Trilogy  Collins, Suzanne   \n",
       "98  Lost Boy,The:A Foster Child's Search for the L...      Pelzer, Dave   \n",
       "99  Jamie's Ministry of Food:Anyone Can Learn to C...     Oliver, Jamie   \n",
       "\n",
       "   Volumes sold        Publisher Genre  \n",
       "0     5,094,805       Transworld     2  \n",
       "1     4,475,152       Bloomsbury     3  \n",
       "2     4,200,654       Bloomsbury     4  \n",
       "3     4,179,479       Bloomsbury     5  \n",
       "4     3,758,936     Random House     6  \n",
       "..          ...              ...   ...  \n",
       "95      807,311     Random House    97  \n",
       "96      794,201          Penguin    98  \n",
       "97      792,187  Scholastic Ltd.    99  \n",
       "98      791,507            Orion   100  \n",
       "99      791,095          Penguin   100  \n",
       "\n",
       "[100 rows x 5 columns]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af18e9dc",
   "metadata": {},
   "source": [
    "### 7. Scrape the details most watched tv series of all time from imdb.com.\n",
    "### Url = https://www.imdb.com/list/ls095964455/\n",
    "### You have to find the following details:\n",
    "### A) Name\n",
    "### B) Year span\n",
    "### C) Genre\n",
    "### D) Run time\n",
    "### E) Ratings\n",
    "### F) Votes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "112550eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "1c6b0982",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_5068\\2947319525.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "#Visiting the website\n",
    "driver.get('https://www.imdb.com/list/ls095964455/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "5c5f1914",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Year=[]\n",
    "Genre=[]\n",
    "Time=[]\n",
    "Rating=[]\n",
    "Votes=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "601d0912",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for Series names\n",
    "try :\n",
    "    name=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/a')\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Name.append('-')\n",
    "#for Series year\n",
    "try :\n",
    "    year=driver.find_elements(By.XPATH,'//h3[@class=\"lister-item-header\"]/span')\n",
    "    for i in year[1:200:2]:\n",
    "        Year.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Year.append('-')\n",
    "#for Series genre\n",
    "try :\n",
    "    genre=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[5]')\n",
    "    for i in genre:\n",
    "        Genre.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Genre.append('-')\n",
    "#for Series Time\n",
    "try :\n",
    "    time=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p/span[3]')\n",
    "    for i in time:\n",
    "        Time.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Time.append('-')\n",
    "#for Series Rating\n",
    "try :\n",
    "    rating=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/div/div/span[2]')\n",
    "    for i in rating:\n",
    "        Rating.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Rating.append('-')\n",
    "#for Series Votes\n",
    "try :\n",
    "    votes=driver.find_elements(By.XPATH,'//div[@class=\"lister-item-content\"]/p[4]/span[2]')\n",
    "    for i in votes:\n",
    "        Votes.append(i.text)\n",
    "except NoSuchElementException :\n",
    "    Votes.append('-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "32040a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Name':Name,'Year Span':Year,'Genre':Genre,'Runtime':Time,'Voting':Votes,'Ratings':Rating})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "a5b195d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Year Span</th>\n",
       "      <th>Genre</th>\n",
       "      <th>Runtime</th>\n",
       "      <th>Voting</th>\n",
       "      <th>Ratings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Game of Thrones</td>\n",
       "      <td>(2011–2019)</td>\n",
       "      <td>Action, Adventure, Drama</td>\n",
       "      <td>57 min</td>\n",
       "      <td>2,162,986</td>\n",
       "      <td>9.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Stranger Things</td>\n",
       "      <td>(2016–2022)</td>\n",
       "      <td>Drama, Fantasy, Horror</td>\n",
       "      <td>51 min</td>\n",
       "      <td>1,242,938</td>\n",
       "      <td>8.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Walking Dead</td>\n",
       "      <td>(2010–2022)</td>\n",
       "      <td>Drama, Horror, Thriller</td>\n",
       "      <td>44 min</td>\n",
       "      <td>1,027,535</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13 Reasons Why</td>\n",
       "      <td>(2017–2020)</td>\n",
       "      <td>Drama, Mystery, Thriller</td>\n",
       "      <td>60 min</td>\n",
       "      <td>302,259</td>\n",
       "      <td>7.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The 100</td>\n",
       "      <td>(2014–2020)</td>\n",
       "      <td>Drama, Mystery, Sci-Fi</td>\n",
       "      <td>43 min</td>\n",
       "      <td>261,371</td>\n",
       "      <td>7.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>Reign</td>\n",
       "      <td>(2013–2017)</td>\n",
       "      <td>Drama</td>\n",
       "      <td>42 min</td>\n",
       "      <td>51,691</td>\n",
       "      <td>7.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>A Series of Unfortunate Events</td>\n",
       "      <td>(2017–2019)</td>\n",
       "      <td>Adventure, Comedy, Drama</td>\n",
       "      <td>50 min</td>\n",
       "      <td>63,726</td>\n",
       "      <td>7.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>Criminal Minds</td>\n",
       "      <td>(2005– )</td>\n",
       "      <td>Crime, Drama, Mystery</td>\n",
       "      <td>42 min</td>\n",
       "      <td>207,711</td>\n",
       "      <td>8.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>Scream: The TV Series</td>\n",
       "      <td>(2015–2019)</td>\n",
       "      <td>Comedy, Crime, Drama</td>\n",
       "      <td>45 min</td>\n",
       "      <td>43,218</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>The Haunting of Hill House</td>\n",
       "      <td>(2018)</td>\n",
       "      <td>Drama, Horror, Mystery</td>\n",
       "      <td>572 min</td>\n",
       "      <td>258,304</td>\n",
       "      <td>8.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Name    Year Span                     Genre  \\\n",
       "0                  Game of Thrones  (2011–2019)  Action, Adventure, Drama   \n",
       "1                  Stranger Things  (2016–2022)    Drama, Fantasy, Horror   \n",
       "2                 The Walking Dead  (2010–2022)   Drama, Horror, Thriller   \n",
       "3                   13 Reasons Why  (2017–2020)  Drama, Mystery, Thriller   \n",
       "4                          The 100  (2014–2020)    Drama, Mystery, Sci-Fi   \n",
       "..                             ...          ...                       ...   \n",
       "95                           Reign  (2013–2017)                     Drama   \n",
       "96  A Series of Unfortunate Events  (2017–2019)  Adventure, Comedy, Drama   \n",
       "97                  Criminal Minds     (2005– )     Crime, Drama, Mystery   \n",
       "98           Scream: The TV Series  (2015–2019)      Comedy, Crime, Drama   \n",
       "99      The Haunting of Hill House       (2018)    Drama, Horror, Mystery   \n",
       "\n",
       "    Runtime     Voting Ratings  \n",
       "0    57 min  2,162,986     9.2  \n",
       "1    51 min  1,242,938     8.7  \n",
       "2    44 min  1,027,535     8.1  \n",
       "3    60 min    302,259     7.5  \n",
       "4    43 min    261,371     7.6  \n",
       "..      ...        ...     ...  \n",
       "95   42 min     51,691     7.4  \n",
       "96   50 min     63,726     7.8  \n",
       "97   42 min    207,711     8.1  \n",
       "98   45 min     43,218       7  \n",
       "99  572 min    258,304     8.6  \n",
       "\n",
       "[100 rows x 6 columns]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42be6628",
   "metadata": {},
   "source": [
    "### 8. Details of Datasets from UCI machine learning repositories.\n",
    "### Url = https://archive.ics.uci.edu/\n",
    "### You have to find the following details:\n",
    "### A) Dataset name\n",
    "### B) Data type\n",
    "### C) Task\n",
    "### D) Attribute type\n",
    "### E) No of instances\n",
    "### F) No of attribute\n",
    "### G) Year\n",
    "### Note: - from the home page you have to go to the ShowAllDataset page through code.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "637b8103",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd\n",
    "import time\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "#Importing selenium webdriver\n",
    "from selenium import webdriver\n",
    "\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "\n",
    "import requests\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "70299cbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\AppData\\Local\\Temp\\ipykernel_9712\\897034582.py:1: DeprecationWarning: executable_path has been deprecated, please pass in a Service object\n",
      "  driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n"
     ]
    }
   ],
   "source": [
    "#Connecting to driver\n",
    "driver=webdriver.Chrome(r\"C:\\Users\\lenovo\\Downloads\\chromedriver_win32\")\n",
    "\n",
    "#Visiting the website\n",
    "driver.get('https://archive.ics.uci.edu/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "29b1cc3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_url=[]\n",
    "url=driver.find_elements(By.XPATH,'//span[@class=\"normal\"]/a')\n",
    "for i in url[9:33]:\n",
    "    product_url.append(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cd7f4c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "Datatype=[]\n",
    "Task=[]\n",
    "Attributetype=[]\n",
    "Instances=[]\n",
    "Attribute=[]\n",
    "Year=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "99285019",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in product_url:\n",
    "    driver.get(i)\n",
    "    time.sleep(1)\n",
    "    #For name\n",
    "    try:\n",
    "        name=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[1]/tbody/tr/td[1]/p[1]/span[1]/b')\n",
    "        Name.append(name.text)\n",
    "    except NoSuchElementException :\n",
    "        Name.append('-')\n",
    "    #For DataType\n",
    "    try:\n",
    "        datatype=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[2]/p')\n",
    "        Datatype.append(datatype.text)\n",
    "    except NoSuchElementException :\n",
    "        Datatype.append('-')\n",
    "    #For Task\n",
    "    try:\n",
    "        task=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[3]/td[2]/p')\n",
    "        Task.append(task.text)\n",
    "    except NoSuchElementException :\n",
    "        Task.append('-')\n",
    "    #For Attributetype\n",
    "    try:\n",
    "        attributetype=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[2]/p')\n",
    "        Attributetype.append(attributetype.text)\n",
    "    except NoSuchElementException :\n",
    "        Attributetype.append('-')\n",
    "    #For Instances\n",
    "    try:\n",
    "        instances=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[1]/td[4]/p')\n",
    "        Instances.append(instances.text)\n",
    "    except NoSuchElementException :\n",
    "        Instances.append('-')\n",
    "    #For Attribute\n",
    "    try:\n",
    "        attribute=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[4]/p')\n",
    "        Attribute.append(attribute.text)\n",
    "    except NoSuchElementException :\n",
    "        Attribute.append('-')\n",
    "     #For Year\n",
    "    try:\n",
    "        year=driver.find_element(By.XPATH,'/html/body/table[2]/tbody/tr/td/table[2]/tbody/tr[2]/td[6]/p')\n",
    "        Year.append(year.text)\n",
    "    except NoSuchElementException :\n",
    "        Year.append('-')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1e1be68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'Dataset Name':Name,'Data Type':Datatype,'Task':Task,'Attribute Type':Attributetype,'No of Instances':Instances,'No of Attributes':Attribute,'Year':Year})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd41b551",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dataset Name</th>\n",
       "      <th>Data Type</th>\n",
       "      <th>Task</th>\n",
       "      <th>Attribute Type</th>\n",
       "      <th>No of Instances</th>\n",
       "      <th>No of Attributes</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9mers from cullpdb Data Set</td>\n",
       "      <td>Sequential</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>158716</td>\n",
       "      <td>4</td>\n",
       "      <td>2021-05-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TamilSentiMix Data Set</td>\n",
       "      <td>N/A</td>\n",
       "      <td>Classification</td>\n",
       "      <td>N/A</td>\n",
       "      <td>15744</td>\n",
       "      <td>N/A</td>\n",
       "      <td>2021-05-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Accelerometer Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>153000</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-05-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Synchronous Machine Data Set Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Synchronous Machine Data Set Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>557</td>\n",
       "      <td>5</td>\n",
       "      <td>2021-04-21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Pedal Me Bicycle Deliveries Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>36</td>\n",
       "      <td>15</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Wikipedia Math Essentials Data Set</td>\n",
       "      <td>Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>731</td>\n",
       "      <td>1068</td>\n",
       "      <td>2021-04-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Turkish Headlines Dataset Data Set</td>\n",
       "      <td>Text</td>\n",
       "      <td>Classification, Clustering</td>\n",
       "      <td>N/A</td>\n",
       "      <td>4200</td>\n",
       "      <td>7</td>\n",
       "      <td>2021-04-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Secondary Mushroom Dataset Data Set</td>\n",
       "      <td>Univariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>61069</td>\n",
       "      <td>21</td>\n",
       "      <td>2021-04-11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Power consumption of Tetouan city Data Set</td>\n",
       "      <td>Multivariate, Time-Series</td>\n",
       "      <td>Regression</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>52417</td>\n",
       "      <td>9</td>\n",
       "      <td>2021-04-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Iris Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>1988-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Adult Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer</td>\n",
       "      <td>48842</td>\n",
       "      <td>14</td>\n",
       "      <td>1996-05-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dry Bean Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>13611</td>\n",
       "      <td>17</td>\n",
       "      <td>2020-09-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Heart Disease Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical, Integer, Real</td>\n",
       "      <td>303</td>\n",
       "      <td>75</td>\n",
       "      <td>1988-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Wine Quality Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification, Regression</td>\n",
       "      <td>Real</td>\n",
       "      <td>4898</td>\n",
       "      <td>12</td>\n",
       "      <td>2009-10-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Wine Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>178</td>\n",
       "      <td>13</td>\n",
       "      <td>1991-07-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Bank Marketing Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>45211</td>\n",
       "      <td>17</td>\n",
       "      <td>2012-02-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Breast Cancer Wisconsin (Diagnostic) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>569</td>\n",
       "      <td>32</td>\n",
       "      <td>1995-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Rice (Cammeo and Osmancik) Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Real</td>\n",
       "      <td>3810</td>\n",
       "      <td>8</td>\n",
       "      <td>2019-10-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Car Evaluation Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Categorical</td>\n",
       "      <td>1728</td>\n",
       "      <td>6</td>\n",
       "      <td>1997-06-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Raisin Dataset Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>Classification</td>\n",
       "      <td>Integer, Real</td>\n",
       "      <td>900</td>\n",
       "      <td>8</td>\n",
       "      <td>2021-04-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Restaurant &amp; consumer data Data Set</td>\n",
       "      <td>Multivariate</td>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "      <td>138</td>\n",
       "      <td>47</td>\n",
       "      <td>2012-08-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Dataset Name                  Data Type  \\\n",
       "0                     9mers from cullpdb Data Set                 Sequential   \n",
       "1                          TamilSentiMix Data Set                        N/A   \n",
       "2                          Accelerometer Data Set               Multivariate   \n",
       "3           Synchronous Machine Data Set Data Set               Multivariate   \n",
       "4           Synchronous Machine Data Set Data Set               Multivariate   \n",
       "5            Pedal Me Bicycle Deliveries Data Set                Time-Series   \n",
       "6              Wikipedia Math Essentials Data Set                Time-Series   \n",
       "7              Wikipedia Math Essentials Data Set                Time-Series   \n",
       "8              Turkish Headlines Dataset Data Set                       Text   \n",
       "9             Secondary Mushroom Dataset Data Set                 Univariate   \n",
       "10     Power consumption of Tetouan city Data Set  Multivariate, Time-Series   \n",
       "11                                  Iris Data Set               Multivariate   \n",
       "12                                 Adult Data Set               Multivariate   \n",
       "13                      Dry Bean Dataset Data Set               Multivariate   \n",
       "14                         Heart Disease Data Set               Multivariate   \n",
       "15                          Wine Quality Data Set               Multivariate   \n",
       "16                                  Wine Data Set               Multivariate   \n",
       "17                        Bank Marketing Data Set               Multivariate   \n",
       "18  Breast Cancer Wisconsin (Diagnostic) Data Set               Multivariate   \n",
       "19            Rice (Cammeo and Osmancik) Data Set               Multivariate   \n",
       "20                        Car Evaluation Data Set               Multivariate   \n",
       "21                        Raisin Dataset Data Set               Multivariate   \n",
       "22            Restaurant & consumer data Data Set               Multivariate   \n",
       "23                                              -                          -   \n",
       "\n",
       "                          Task              Attribute Type No of Instances  \\\n",
       "0   Classification, Regression                        Real          158716   \n",
       "1               Classification                         N/A           15744   \n",
       "2   Classification, Regression               Integer, Real          153000   \n",
       "3                   Regression                        Real             557   \n",
       "4                   Regression                        Real             557   \n",
       "5                   Regression                        Real              36   \n",
       "6                   Regression                        Real             731   \n",
       "7                   Regression                        Real             731   \n",
       "8   Classification, Clustering                         N/A            4200   \n",
       "9               Classification                        Real           61069   \n",
       "10                  Regression               Integer, Real           52417   \n",
       "11              Classification                        Real             150   \n",
       "12              Classification        Categorical, Integer           48842   \n",
       "13              Classification               Integer, Real           13611   \n",
       "14              Classification  Categorical, Integer, Real             303   \n",
       "15  Classification, Regression                        Real            4898   \n",
       "16              Classification               Integer, Real             178   \n",
       "17              Classification                        Real           45211   \n",
       "18              Classification                        Real             569   \n",
       "19              Classification                        Real            3810   \n",
       "20              Classification                 Categorical            1728   \n",
       "21              Classification               Integer, Real             900   \n",
       "22                         N/A                         N/A             138   \n",
       "23                           -                           -               -   \n",
       "\n",
       "   No of Attributes        Year  \n",
       "0                 4  2021-05-25  \n",
       "1               N/A  2021-05-18  \n",
       "2                 5  2021-05-02  \n",
       "3                 5  2021-04-21  \n",
       "4                 5  2021-04-21  \n",
       "5                15  2021-04-20  \n",
       "6              1068  2021-04-20  \n",
       "7              1068  2021-04-20  \n",
       "8                 7  2021-04-14  \n",
       "9                21  2021-04-11  \n",
       "10                9  2021-04-03  \n",
       "11                4  1988-07-01  \n",
       "12               14  1996-05-01  \n",
       "13               17  2020-09-14  \n",
       "14               75  1988-07-01  \n",
       "15               12  2009-10-07  \n",
       "16               13  1991-07-01  \n",
       "17               17  2012-02-14  \n",
       "18               32  1995-11-01  \n",
       "19                8  2019-10-06  \n",
       "20                6  1997-06-01  \n",
       "21                8  2021-04-01  \n",
       "22               47  2012-08-04  \n",
       "23                -           -  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
